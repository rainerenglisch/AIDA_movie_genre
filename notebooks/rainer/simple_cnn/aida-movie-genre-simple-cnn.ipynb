{"cells":[{"metadata":{"id":"kJCMwRx9_4rN"},"cell_type":"markdown","source":"# Baseline (01)"},{"metadata":{"id":"M7yzKetZAK3s"},"cell_type":"markdown","source":"# Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install gdown","execution_count":null,"outputs":[]},{"metadata":{"id":"iLciMje9AOmB","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport gdown\n\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow_addons as tfa\n\n\n#from wcs.google import google_drive_share\nimport pandas as pd\nimport urllib.request\nfrom urllib.parse import urlparse\n\n#from google.colab import drive\n\n\nimport warnings\nwarnings.simplefilter(action='ignore')\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{"id":"YcfsOKfzC2N6"},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"id":"SRMNiJ9oMGY2","trusted":true},"cell_type":"code","source":"BASE_DIR =\"./\"\n#IMAGES_DIR = \"/kaggle/input/movie-poster-genre-2021/images/\"\nIMAGES_DIR = \"/kaggle/input/moviepostergenre20212/images/images/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!ls $IMAGES_DIR","execution_count":null,"outputs":[]},{"metadata":{"id":"eA1fV-j_KX0L"},"cell_type":"markdown","source":"# Preproc"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://drive.google.com/file/d/1MlXZKtRUP7pOehDR9j5MMvBNXF4UNNUx/view?usp=sharing\nurl = 'https://drive.google.com/uc?id=1MlXZKtRUP7pOehDR9j5MMvBNXF4UNNUx'\nholdout_fname = \"df_holdout.csv\"\nif not os.path.exists(holdout_fname):\n    gdown.download(url, holdout_fname, quiet=False)\n    df_holdout = pd.read_csv(holdout_fname,sep=\";\")\n    df_holdout.head()\n\n#Bitte diese 1000 Movie IDs vom Training und vom gesamten Model Engineering ausschließen und \n#nur für die Einträge im Leaderboard verwenden.","execution_count":null,"outputs":[]},{"metadata":{"id":"oE24fz77duaZ","trusted":true},"cell_type":"code","source":"def retrieve_filename(url):\n    a = urlparse(url)\n    picfilename = os.path.basename(a.path)\n    return picfilename\n","execution_count":null,"outputs":[]},{"metadata":{"id":"acVfQ8KqKlaI","trusted":true},"cell_type":"code","source":"parquet_fname = \"./df.parquet.gzip\"\nos.path.exists(parquet_fname)\n#!rm $parquet_fname","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"url = 'https://drive.google.com/uc?id=1ynvEZMYRonM2SuJ9mQ4kCkznMW6dsqcA'\ngdown.download(url, parquet_fname, quiet=False)\ndf = pd.read_parquet(parquet_fname)\ndf['genre_id'] = df['genre_id'].apply(lambda x: list(x))\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#https://drive.google.com/file/d/178mXeXUC1400lj-LrWyhD3yfW5_KsVYw/view?usp=sharing\nif not os.path.exists(parquet_fname):\n    url = 'https://drive.google.com/uc?id=178mXeXUC1400lj-LrWyhD3yfW5_KsVYw'\n    gdown.download(url, parquet_fname, quiet=False)\n    df = pd.read_parquet(parquet_fname)\n    \n    df[\"filename\"] = df.loc[~df[\"poster_url\"].isnull(),\"poster_url\"].apply(retrieve_filename)\n    \n    # use only mot null rows\n    df = df.dropna()\n    # set data path to basename of the file\n    #df['data_path'] = df['poster_path'].apply(lambda x: x.split('/')[-1])\n    # remove rows with empty genre_id list and set correct list type\n    df['genre_id'] = df['genre_id'].apply(lambda x: np.nan if len(eval(x)) == 0 else x)\n    #df = df.dropna()\n    df['genre_id'] = df['genre_id'].apply(lambda x: eval(x))\n\n    print(f'len of df: {len(df)}')\n    print(\"Checking existence of images\")\n    df[\"file_exists\"] = df[\"filename\"].apply(lambda x: os.path.exists(IMAGES_DIR + x))\n    print(\"Flagging hold out images\")\n    df[\"is_holdout\"] = False\n    df.loc[df[\"id\"].isin(df_holdout[\"id\"]),\"is_holdout\"] = True\n\n    df.to_parquet(parquet_fname,compression='gzip')\nelse:\n    df = pd.read_parquet(\"./df.parquet.gzip\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['genre_id'] = df['genre_id'].apply(lambda x: list(x))\n\ntype(df[\"genre_id\"].iloc[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.is_holdout.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.file_exists.value_counts()\n#print(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#keep only rows where file exists in data set\ndf = df.loc[df[\"file_exists\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[~df.is_holdout].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.is_holdout].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.is_holdout].head()","execution_count":null,"outputs":[]},{"metadata":{"id":"v1ChqgNRK0py"},"cell_type":"markdown","source":" Create ImageGenerators"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGES_DIR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndatagen = ImageDataGenerator(rescale=1 / 255.)#, validation_split=0.1)\nBATCH_SIZE = 64\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=df.loc[~df.is_holdout],\n    directory=IMAGES_DIR,\n    x_col=\"filename\",\n    y_col=\"genre_id\",\n    batch_size=BATCH_SIZE,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",    \n    target_size=(299, 299),\n    subset='training',\n    validate_filenames=False\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#datagen = ImageDataGenerator(rescale=1 / 255.)#, validation_split=0.1)\nvalid_generator = datagen.flow_from_dataframe(\n    dataframe=df.loc[df.is_holdout],\n    directory=IMAGES_DIR,\n    x_col=\"filename\",\n    y_col=\"genre_id\",\n    batch_size=BATCH_SIZE,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(299, 299),\n    subset='training',\n    validate_filenames=False\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"tz11Ruq2KyQs","trusted":true},"cell_type":"markdown","source":"%%time\ndatagen = ImageDataGenerator(rescale=1 / 255., validation_split=0.1)\nBATCH_SIZE = 64\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=IMAGES_DIR,\n    x_col=\"filename\",\n    y_col=\"genre_id\",\n    batch_size=BATCH_SIZE,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",    \n    target_size=(299, 299),\n    subset='training',\n    validate_filenames=True\n)\n\nvalid_generator = datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=IMAGES_DIR,\n    x_col=\"filename\",\n    y_col=\"genre_id\",\n    batch_size=BATCH_SIZE,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(299, 299),\n    subset='validation',\n    validate_filenames=True\n)"},{"metadata":{"id":"1a6YhAuOLWFC","trusted":true},"cell_type":"code","source":"# show class indicies\nprint(train_generator.class_indices)\nprint('length:', len(train_generator.class_indices))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"irTOneeqduah","trusted":true},"cell_type":"code","source":"list(train_generator.class_indices.keys())","execution_count":null,"outputs":[]},{"metadata":{"id":"SIVWsXqFduai","trusted":true},"cell_type":"code","source":"#https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras\nfrom sklearn.utils import class_weight\n#In order to calculate the class weight do the following\n\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                  np.array(list(train_generator.class_indices.keys()),dtype=\"int\"), \n                                                  np.array(df.genre_id.explode(),dtype=\"int\"))\n\nclass_weights_genre_id = dict(zip(list(train_generator.class_indices), class_weights))\ndisplay(class_weights_genre_id)\nclass_weights = dict(zip(list(range(len(class_weights))), class_weights))\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"id":"MXYlHNqVduaj","trusted":true},"cell_type":"code","source":"map_gender={\"28\":\"Action\",\n\"12\":\"Adventure\",\n\"16\":\"Animation\",\n\"35\":\"Comedy\",\n\"80\":\"Crime\",\n\"99\":\"Documentary\",\n\"18\":\"Drama\",\n\"10751\":\"Family\",\n\"14\":\"Fantasy\",\n\"36\":\t\"History\",\n\"27\":\"Horror\",\n\"10402\"\t:\"Music\",\n\"9648\":\"Mystery\",\n\"10749\":\"Romance\",\n\"878\"\t:\"Science Fiction\",\n\"10770\":\"TV Movie\",\n\"53\":\"Thriller\",\n\"10752\":\"War\",\n\"37\":\"Western\"}\n\nseries_genre_id_counts = df.genre_id.explode().value_counts()\nseries_genre_id_counts\ndf_genre = pd.DataFrame(series_genre_id_counts)\ndf_genre[\"id\"] = df_genre.index\ndf_genre.rename(columns={\"genre_id\" : \"count\"},inplace=True)\ndf_genre[\"name\"] = df_genre[\"id\"].apply(lambda x : map_gender[str(x)])\ndf_genre[\"weight\"] = df_genre[\"id\"].apply(lambda x : class_weights_genre_id[x])\ndf_genre.sort_values(by=\"count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"4Uc9-PAmduar","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"cPXBrisCLgl2"},"cell_type":"markdown","source":"# Simple Model"},{"metadata":{"id":"SL2yeEslLcMe","trusted":true},"cell_type":"code","source":"model = keras.Sequential(\n    [\n      layers.Conv2D(32, (3, 3), padding='same', input_shape=(299, 299, 3)),\n      layers.Activation('relu'),\n      layers.Conv2D(32, (3, 3)),\n      layers.Activation('relu'),\n      layers.MaxPooling2D(pool_size=(2, 2)),\n      layers.Dropout(0.25),\n      layers.Conv2D(64, (3, 3), padding='same'),\n      layers.Activation('relu'),\n      layers.Conv2D(64, (3, 3)),\n      layers.Activation('relu'),\n      layers.MaxPooling2D(pool_size=(2, 2)),\n      layers.Dropout(0.25),\n      layers.Flatten(),\n      layers.Dense(512),\n      layers.Activation('relu'),\n      layers.Dropout(0.5),\n      layers.Dense(len(train_generator.class_indices), activation='sigmoid')\n    ]\n)\n\n\n#model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"e8DgtGWiduau"},"cell_type":"markdown","source":"model = keras.Sequential(\n    [ \n        layers.Conv2D(32, (3, 3), padding='same', input_shape=(299, 299, 3)),\n        layers.Activation('relu'),\n        layers.Conv2D(64, (3, 3), activation='relu'),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Dropout(0.25),\n        layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n        layers.Conv2D(64, (3, 3), activation='relu'),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Dropout(0.25),\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(len(train_generator.class_indices), activation='sigmoid')\n        #layers.Dense(len(train_generator.class_indices), activation='softmax')\n\n    ])"},{"metadata":{"id":"nKhnvQ75dubS","trusted":true},"cell_type":"code","source":"#model = Model(inputs=model.inputs, outputs=classifications)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_micro = tfa.metrics.F1Score(num_classes=19, average='micro', name='f1_micro'), \nf1_macro = tfa.metrics.F1Score(num_classes=19, average='macro', name='f1_macro')\nf1_weighted = tfa.metrics.F1Score(num_classes=19,  average='weighted', name='f1_score_weighted')","execution_count":null,"outputs":[]},{"metadata":{"id":"PALSOI_Sjd45","trusted":true},"cell_type":"code","source":"import os.path\n\nfname_model = BASE_DIR + \"CNN_Simple_1\"\n\nif  os.path.exists(fname_model) :\n    print(\"Load model\")\n    model = keras.models.load_model(fname_model, custom_objects={'_tf_keras_metric':f1_micro})\n","execution_count":null,"outputs":[]},{"metadata":{"id":"c0lPlJz1dubT","trusted":true},"cell_type":"code","source":"from keras import metrics\n#https://neptune.ai/blog/keras-metrics\nmodel.compile(optimizer='adam', loss=\"binary_crossentropy\", \n              metrics=[\"categorical_accuracy\",\n                       tf.keras.metrics.AUC(multi_label = True),#,label_weights=class_weights),\n                        f1_micro,\n                        f1_macro,\n                        f1_weighted,\n                      ])","execution_count":null,"outputs":[]},{"metadata":{"id":"vIRDrzYqM_Vw"},"cell_type":"markdown","source":"# Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir model_checkpoints","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\nfilepath = \"model_checkpoints/saved-model-{epoch:02d}-{val_f1_score_weighted:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_f1_score_weighted', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"id":"-6NBrltEM2Xy","outputId":"41257bb9-d813-470d-8c4c-a8a5b5534007","trusted":true},"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    validation_data=valid_generator,\n    epochs=10,# 5,\n    #batch_size=BATCH_SIZE,\n    #steps_per_epoch=10,#1430,\n    class_weight = class_weights,\n    callbacks=callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir final_model\n!mkdir final_model_weights","execution_count":null,"outputs":[]},{"metadata":{"id":"eL6vW2zjji4o","trusted":true},"cell_type":"code","source":"print(\"Saving final model\")\nmodel.save(\"final_model/\" + fname_model)\nprint(\"Saving final model weights\")\nmodel.save_weights(\"final_model_weights/\" + fname_model + \".ckpt\")\n#load_status = sequential_model.load_weights(\"ckpt\")","execution_count":null,"outputs":[]},{"metadata":{"id":"eQJFXU5DdubU","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}