{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as klay\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "#https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.densenet import DenseNet169\n",
    "\n",
    "#from wcs.google import google_drive_share\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import src.helper.helper as hlp\n",
    "import src.helper.const as const\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "DIR = './'\n",
    "DATA_DIR_POSTER = DIR + '../data/raw/posters/'\n",
    "DATA_DIR_INTERIM = DIR + \"../data/interim/\"\n",
    "DATA_DIR_RAW = DIR + \"../data/raw/\"\n",
    "MODEL_DIR = DIR + \"../models/\"\n",
    "BASE_DIR = DIR\n",
    "IMAGES_DIR = DATA_DIR_POSTER\n",
    "SEED = const.SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "No GPU available\n",
      "CPUs will be automatically choosen for model calculations below.\n"
     ]
    }
   ],
   "source": [
    "# Check GPUs\n",
    "num_gpu = len(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", num_gpu)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"{f'Physical GPU Device: {gpus}' if gpus else 'No GPU available'}\")\n",
    "\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 6GB of memory on the first GPU\n",
    "    try:\n",
    "        \"\"\"\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Set memory growth for {len(gpus)} physical GPU(s)\")\n",
    "        \"\"\"\n",
    "        mem_lim = 10*1024  # 6GB\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=mem_lim)])        \n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"Set memory usage to {mem_lim/1000} GB for {len(gpus)} physical GPU(s) -> {len(logical_gpus)} logical GPU(s)\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "    print(\"GPU(s) will be automatically choosen for model calculations below.\")\n",
    "else:\n",
    "    print(\"CPUs will be automatically choosen for model calculations below.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "classes should include all valid labels that can be in y",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-55a9440dc0bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m class_weights = class_weight.compute_class_weight('balanced',\n\u001b[0;32m     37\u001b[0m                                                   \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                                                   np.array(df.genre_id.explode(),dtype=\"int\"))\n\u001b[0m\u001b[0;32m     39\u001b[0m                                                  \u001b[1;31m#np.unique(y_train),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                                                  \u001b[1;31m#y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\anaconda3\\envs\\aida\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\anaconda3\\envs\\aida\\lib\\site-packages\\sklearn\\utils\\class_weight.py\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[1;34m(class_weight, classes, y)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         raise ValueError(\"classes should include all valid labels that can \"\n\u001b[0m\u001b[0;32m     45\u001b[0m                          \"be in y\")\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: classes should include all valid labels that can be in y"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df = pd.read_parquet(DATA_DIR_INTERIM + \"df_train_balanced_v3.gzip\")\n",
    "\n",
    "# Setuup data generators\n",
    "datagen = ImageDataGenerator(rescale=1 / 255., validation_split=0.1)\n",
    "BATCH_SIZE = 64*8\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=IMAGES_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"genre_id\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(299, 299),\n",
    "    subset='training',\n",
    "    validate_filenames=True\n",
    ")\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=IMAGES_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"genre_id\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(299, 299),\n",
    "    subset='validation',\n",
    "    validate_filenames=True\n",
    ")\n",
    "\n",
    "# Setup class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.array(list(train_generator.class_indices.keys()),dtype=\"int\"), \n",
    "                                                  np.array(df.genre_id.explode(),dtype=\"int\"))\n",
    "                                                 #np.unique(y_train),\n",
    "                                                 #y_train)\n",
    "class_weights_genre_id = dict(zip(list(train_generator.class_indices), class_weights))\n",
    "display(class_weights_genre_id)\n",
    "class_weights = dict(zip(list(range(len(class_weights))), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build model\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Use different multi GPU strategies\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce())\n",
    "strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "#strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "runtime_context = strategy.scope()\n",
    "\n",
    "# Use one GPU\n",
    "#runtime_context = tf.device(\"/GPU:0\")\n",
    "\n",
    "# Usa all CPUs\n",
    "#runtime_context = tf.device(\"/CPU:0\")\n",
    "\n",
    "with runtime_context:    \n",
    "    # Build model\n",
    "    inputs = klay.Input(shape=(299, 299, 3), name=\"Input\")\n",
    "    x = klay.Conv2D(\n",
    "        filters=32,  # channels\n",
    "        kernel_size=(3, 3),  # convolutional matrix\n",
    "        name='Conv_1')(inputs)\n",
    "\n",
    "    x = klay.MaxPool2D(\n",
    "        pool_size=(2,2),\n",
    "        name='MaxPool_1')(x)\n",
    "\n",
    "    x = klay.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        name='Conv_2')(x)\n",
    "\n",
    "    x = klay.MaxPool2D(\n",
    "        pool_size=(2,2),\n",
    "        name='MaxPool_2')(x)\n",
    "\n",
    "    x = klay.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        name='Conv_3')(x)\n",
    "\n",
    "    x = klay.Flatten(\n",
    "        name='Flatten')(x)\n",
    "\n",
    "    x = klay.Dense(\n",
    "        64,\n",
    "        activation='relu',\n",
    "        name='Dense')(x)\n",
    "\n",
    "    outputs = klay.Dense(\n",
    "        len(train_generator.class_indices),\n",
    "        activation='sigmoid',\n",
    "        name='Output')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"CNN\")\n",
    "   \n",
    "    print(model.summary())\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss=\"binary_crossentropy\", \n",
    "          metrics=[metrics.categorical_accuracy,\n",
    "                   tf.keras.metrics.AUC(),\n",
    "                   tf.keras.metrics.Precision(), \n",
    "                   tf.keras.metrics.Recall(),\n",
    "                   hlp.f1_m,\n",
    "                  ])\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=valid_generator,\n",
    "        epochs=1,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        #steps_per_epoch=1430,\n",
    "        class_weight = class_weights\n",
    "    )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
