{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stylish-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as klay\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "#https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.densenet import DenseNet169\n",
    "\n",
    "#from wcs.google import google_drive_share\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import src.helper.helper as hlp\n",
    "import src.helper.const as const\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medical-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "DIR = './'\n",
    "DATA_DIR_POSTER = DIR + '../data/raw/posters_v3/'\n",
    "DATA_DIR_INTERIM = DIR + \"../data/interim/\"\n",
    "DATA_DIR_RAW = DIR + \"../data/raw/\"\n",
    "MODEL_DIR = DIR + \"../models/\"\n",
    "BASE_DIR = DIR\n",
    "IMAGES_DIR = DATA_DIR_POSTER\n",
    "SEED = const.SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "given-shower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n",
      "Physical GPU Device: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "Set memory usage to 10.24 GB for 2 physical GPU(s) -> 2 logical GPU(s)\n",
      "GPU(s) will be automatically choosen for model calculations below.\n"
     ]
    }
   ],
   "source": [
    "# Check GPUs\n",
    "num_gpu = len(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", num_gpu)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"{f'Physical GPU Device: {gpus}' if gpus else 'No GPU available'}\")\n",
    "\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 6GB of memory on the first GPU\n",
    "    try:\n",
    "        \"\"\"\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Set memory growth for {len(gpus)} physical GPU(s)\")\n",
    "        \"\"\"\n",
    "        mem_lim = 10*1024  # 6GB\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=mem_lim)])        \n",
    "        #logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        #print(f\"Set memory usage to {mem_lim/1000} GB for {len(gpus)} physical GPU(s) -> {len(logical_gpus)} logical GPU(s)\")\n",
    "        print(f\"Set memory usage to {mem_lim/1000} GB for {len(gpus)} physical GPU(s)\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "    print(\"GPU(s) will be automatically choosen for model calculations below.\")\n",
    "else:\n",
    "    print(\"CPUs will be automatically choosen for model calculations below.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "precious-damage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13239 validated image filenames belonging to 19 classes.\n",
      "Found 1470 validated image filenames belonging to 19 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{12: 0.9582155284906481,\n",
       " 14: 1.2180599232816118,\n",
       " 16: 1.060666245373296,\n",
       " 18: 0.3579902090231368,\n",
       " 27: 1.0810636731689363,\n",
       " 28: 0.7519680839715828,\n",
       " 35: 0.5943945091822797,\n",
       " 36: 1.5446338577501204,\n",
       " 37: 2.0033534159372515,\n",
       " 53: 0.8413175796634443,\n",
       " 80: 1.1215872207726088,\n",
       " 99: 1.2500709320470988,\n",
       " 878: 1.2785012151329391,\n",
       " 9648: 1.340393976270155,\n",
       " 10402: 1.5106720384021943,\n",
       " 10749: 0.9572266579762099,\n",
       " 10751: 1.1188813408672464,\n",
       " 10752: 1.6926142912024587,\n",
       " 10770: 1.396916613823716}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df = pd.read_parquet(DATA_DIR_INTERIM + \"df_train_balanced_v3.gzip\")\n",
    "\n",
    "# Setuup data generators\n",
    "datagen = ImageDataGenerator(rescale=1 / 255., validation_split=0.1)\n",
    "BATCH_SIZE = 64*8\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=IMAGES_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"genre_id\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(299, 299),\n",
    "    subset='training',\n",
    "    validate_filenames=True\n",
    ")\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=IMAGES_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"genre_id\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(299, 299),\n",
    "    subset='validation',\n",
    "    validate_filenames=True\n",
    ")\n",
    "\n",
    "# Setup class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.array(list(train_generator.class_indices.keys()),dtype=\"int\"), \n",
    "                                                  np.array(df.genre_id.explode(),dtype=\"int\"))\n",
    "                                                 #np.unique(y_train),\n",
    "                                                 #y_train)\n",
    "class_weights_genre_id = dict(zip(list(train_generator.class_indices), class_weights))\n",
    "display(class_weights_genre_id)\n",
    "class_weights = dict(zip(list(range(len(class_weights))), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fantastic-flesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'], variable_device = '/device:CPU:0'\n",
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv_1 (Conv2D)              (None, 297, 297, 32)      896       \n",
      "_________________________________________________________________\n",
      "MaxPool_1 (MaxPooling2D)     (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 146, 146, 64)      18496     \n",
      "_________________________________________________________________\n",
      "MaxPool_2 (MaxPooling2D)     (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 71, 71, 128)       73856     \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 645248)            0         \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 64)                41295936  \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 19)                1235      \n",
      "=================================================================\n",
      "Total params: 41,390,419\n",
      "Trainable params: 41,390,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "26/26 [==============================] - 204s 8s/step - loss: 2.9567 - categorical_accuracy: 0.1487 - auc: 0.5039 - precision: 0.1266 - recall: 0.1861 - f1_m: 0.1121 - val_loss: 0.6891 - val_categorical_accuracy: 0.2565 - val_auc: 0.5427 - val_precision: 0.1279 - val_recall: 0.0114 - val_f1_m: 0.0206\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build model\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Use different multi GPU strategies\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce())\n",
    "strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "#strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "runtime_context = strategy.scope()\n",
    "\n",
    "# Use one GPU\n",
    "#runtime_context = tf.device(\"/GPU:0\")\n",
    "\n",
    "# Usa all CPUs\n",
    "#runtime_context = tf.device(\"/CPU:0\")\n",
    "\n",
    "with runtime_context:    \n",
    "    # Build model\n",
    "    inputs = klay.Input(shape=(299, 299, 3), name=\"Input\")\n",
    "    x = klay.Conv2D(\n",
    "        filters=32,  # channels\n",
    "        kernel_size=(3, 3),  # convolutional matrix\n",
    "        name='Conv_1')(inputs)\n",
    "\n",
    "    x = klay.MaxPool2D(\n",
    "        pool_size=(2,2),\n",
    "        name='MaxPool_1')(x)\n",
    "\n",
    "    x = klay.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        name='Conv_2')(x)\n",
    "\n",
    "    x = klay.MaxPool2D(\n",
    "        pool_size=(2,2),\n",
    "        name='MaxPool_2')(x)\n",
    "\n",
    "    x = klay.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        name='Conv_3')(x)\n",
    "\n",
    "    x = klay.Flatten(\n",
    "        name='Flatten')(x)\n",
    "\n",
    "    x = klay.Dense(\n",
    "        64,\n",
    "        activation='relu',\n",
    "        name='Dense')(x)\n",
    "\n",
    "    outputs = klay.Dense(\n",
    "        len(train_generator.class_indices),\n",
    "        activation='sigmoid',\n",
    "        name='Output')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"CNN\")\n",
    "   \n",
    "    print(model.summary())\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss=\"binary_crossentropy\", \n",
    "          metrics=[metrics.categorical_accuracy,\n",
    "                   tf.keras.metrics.AUC(),\n",
    "                   tf.keras.metrics.Precision(), \n",
    "                   tf.keras.metrics.Recall(),\n",
    "                   hlp.f1_m,\n",
    "                  ])\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=valid_generator,\n",
    "        epochs=1,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        #steps_per_epoch=1430,\n",
    "        class_weight = class_weights\n",
    "    )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-colonial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-hurricane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-yeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-creativity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
