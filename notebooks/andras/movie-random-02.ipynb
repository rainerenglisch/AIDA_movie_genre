{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow_addons as tfa\n\nimport pandas as pd\nimport urllib.request\nfrom urllib.parse import urlparse\n\nimport warnings\nwarnings.simplefilter(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_parquet('../input/movie-posters-2/df_train-split_v1.gzip')\ndf_val = pd.read_parquet('../input/movie-posters-2/df_eval-split_v1.gzip')\ndf_test = pd.read_parquet('../input/movie-posters-2/df_test-split_v1.gzip')\n\ndef get_path_from_url(url):\n    if url is None:\n        return None    \n    return url.split('/')[-1]\n\ndf_train['filename'] = df_train['poster_url'].apply(get_path_from_url)\ndf_val['filename'] = df_val['poster_url'].apply(get_path_from_url)\ndf_test['filename'] = df_test['poster_url'].apply(get_path_from_url)\n\ndisplay(df_train.head(2))\ndisplay(df_val.head(2))\ndisplay(df_test.head(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_val.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Image generators for train, validate and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGES_DIR = '../input/movie-posters-2/data'\n\nlabel_cols = [col for col in df_train.columns if col.startswith('x0_')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator()\n\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=df_train,\n    directory=IMAGES_DIR,\n    x_col=\"filename\",\n    y_col=label_cols,\n    batch_size=64,\n    shuffle=True,\n    class_mode=\"raw\",    \n    target_size=(299, 299),\n)\n\nvalid_generator = datagen.flow_from_dataframe(\n    dataframe=df_val,\n    directory=IMAGES_DIR,\n    x_col=\"filename\",\n    y_col=label_cols,\n    batch_size=64,\n    class_mode=\"raw\",\n    target_size=(299, 299)\n)\n\ntest_generator = datagen.flow_from_dataframe(\n    dataframe=df_test,\n    directory=IMAGES_DIR,\n    x_col=\"filename\",\n    y_col=label_cols,\n    batch_size=64,\n    class_mode=\"raw\",\n    target_size=(299, 299),\n    validate_filenames=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Random Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"m1 = keras.Sequential()\nm1.add(\n    layers.Lambda(lambda x: tf.random.uniform((1,19), minval=0.0, maxval=1.0), input_shape=(299,299,3))\n    )\nm1.compile(optimizer='adam', loss='binary_crossentropy', \n           metrics=['accuracy',\n                    tfa.metrics.FBetaScore(num_classes=19, average='micro', threshold=0.5, name='f1_score_micro',),\n                    tfa.metrics.FBetaScore(num_classes=19, average='weighted', threshold=0.5, name='f1_score_weighted'),])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m1.evaluate(test_generator)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}