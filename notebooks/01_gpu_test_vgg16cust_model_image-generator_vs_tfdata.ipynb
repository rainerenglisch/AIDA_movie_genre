{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJCMwRx9_4rN"
   },
   "source": [
    "> # AIDA with Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7yzKetZAK3s"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iLciMje9AOmB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "#https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.densenet import DenseNet169\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from numba import cuda\n",
    "\n",
    "import sklearn.model_selection as skms\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#from wcs.google import google_drive_share\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "#from google.colab import drive\n",
    "import src.helper.helper as hlp\n",
    "import src.helper.const as const\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcfsOKfzC2N6"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "DP_TFDATA = \"Data pipeline using tf.data\"\n",
    "DP_IMGGEN = \"Data pipeline using tf.keras.ImageGenerator\"\n",
    "DP = DP_IMGGEN\n",
    "\n",
    "LR = 1e-5 # Keep it small when transfer learning\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 2\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE  # Adapt preprocessing and prefetching dynamically to reduce GPU and CPU idle time\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations\n",
    "\n",
    "IMG_DIMS = [299, 299]\n",
    "IMG_CHANNELS = 3  # Keep RGB color channels to match the input format of the model\n",
    "LABEL_COLS = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n",
    "              'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror',\n",
    "              'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie',\n",
    "              'Thriller', 'War', 'Western']\n",
    "\n",
    "DIR = './'\n",
    "DATA_DIR_POSTER = DIR + '../data/raw/posters_v3/'\n",
    "DATA_DIR_INTERIM = DIR + \"../data/interim/\"\n",
    "DATA_DIR_RAW = DIR + \"../data/raw/\"\n",
    "MODEL_DIR = DIR + \"../models/\"\n",
    "BASE_DIR = DIR\n",
    "IMAGES_DIR = DATA_DIR_POSTER\n",
    "SEED = const.SEED\n",
    "TENSORBOARD_LOGDIR = DIR + \"tensorboard_logs/scalars/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPU, 4 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Create virtual GPUs\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            #OK, but solwer: \n",
    "            #gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024)],\n",
    "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024),\n",
    "                      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)],\n",
    "            #Error: gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10*1024)],\n",
    "        )\n",
    "        \n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            #OK, but solwer: \n",
    "            #gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "            #      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024)],\n",
    "            gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024),\n",
    "                      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)],\n",
    "            #Error: gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10*1024)],            \n",
    "        )\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_devices():\n",
    "    # Check GPUs\n",
    "    num_gpu = len(tf.config.list_physical_devices('GPU'))\n",
    "    print(\"Num GPUs Available: \", num_gpu)\n",
    "\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"{f'Physical GPU Device: {gpus}' if gpus else 'No GPU available'}\")\n",
    "\n",
    "    if gpus:\n",
    "        # Restrict TensorFlow to only allocate 6GB of memory on the first GPU\n",
    "        try:\n",
    "            \"\"\"\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"Set memory growth for {len(gpus)} physical GPU(s)\")\n",
    "            \"\"\"\n",
    "            mem_lim = 10*1024  # 6GB\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpus[0],\n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=mem_lim)])        \n",
    "            #logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            #print(f\"Set memory usage to {mem_lim/1000} GB for {len(gpus)} physical GPU(s) -> {len(logical_gpus)} logical GPU(s)\")\n",
    "            print(f\"Set memory usage to {mem_lim/1000} GB for {len(gpus)} physical GPU(s)\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            # Virtual devices must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "        print(\"GPU(s) will be automatically choosen for model calculations below.\")\n",
    "    else:\n",
    "        print(\"CPUs will be automatically choosen for model calculations below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datapipeline based on tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename, label):\n",
    "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
    "    Args:\n",
    "        filename: string representing path to image\n",
    "        label: 0/1 one-dimensional array of size N_LABELS\n",
    "    \"\"\"\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(DATA_DIR_POSTER + filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=IMG_CHANNELS)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_DIMS[0], IMG_DIMS[1]])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized, label\n",
    "\n",
    "\n",
    "def create_dataset(filenames, labels, cache=True):\n",
    "    \"\"\"Load and parse dataset.\n",
    "    Args:\n",
    "        filenames: list of image paths\n",
    "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if cache == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "        \n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA1fV-j_KX0L"
   },
   "source": [
    "# Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "acVfQ8KqKlaI"
   },
   "outputs": [],
   "source": [
    "#parquet_fname = DATA_DIR_INTERIM + \"df_train_unbalanced_v3.gzip\"\n",
    "parquet_fname = DATA_DIR_INTERIM + \"df_train_balanced_v3.gzip\"\n",
    "#!rm $parquet_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>video</th>\n",
       "      <th>url</th>\n",
       "      <th>poster_url</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>filename</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>genre_ids2</th>\n",
       "      <th>genre_ids2_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>52826</td>\n",
       "      <td>Nothing Lasts Forever</td>\n",
       "      <td>5.658</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/52826</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//ph2L3Rp3X...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ph2L3Rp3XbMzxuLTTQBxvtNgF13.jpg</td>\n",
       "      <td>[878, 35, 14]</td>\n",
       "      <td>[Science Fiction,Comedy,Fantasy]</td>\n",
       "      <td>[Science Fiction, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>460059</td>\n",
       "      <td>Burn Out</td>\n",
       "      <td>32.045</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/460059</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//3LeFOvzjZ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3LeFOvzjZuIC7cQiXDeSIy1ym7a.jpg</td>\n",
       "      <td>[28, 53]</td>\n",
       "      <td>[Action,Thriller]</td>\n",
       "      <td>[Action, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>86674</td>\n",
       "      <td>パーク アンド ラブホテル</td>\n",
       "      <td>1.677</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/86674</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//8KAgoOwi3...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8KAgoOwi3KVtp8pwnmtsfoQSkEh.jpg</td>\n",
       "      <td>[18, 10749]</td>\n",
       "      <td>[Drama,Romance]</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>169298</td>\n",
       "      <td>Bullet</td>\n",
       "      <td>11.017</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/169298</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//oSYnKLSl1...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>oSYnKLSl11aoZqJQIK9zoV63l3D.jpg</td>\n",
       "      <td>[28, 80, 53]</td>\n",
       "      <td>[Action,Crime,Thriller]</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>550654</td>\n",
       "      <td>Every Other Holiday</td>\n",
       "      <td>6.878</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/550654</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//8DetMslOB...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8DetMslOBOBKsT2cXBDBHP0ayVF.jpg</td>\n",
       "      <td>[10770, 10751, 10749, 18]</td>\n",
       "      <td>[TV Movie,Family,Romance,Drama]</td>\n",
       "      <td>[TV Movie, Family, Romance, Drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult      id         original_title  popularity  video  \\\n",
       "0  False   52826  Nothing Lasts Forever       5.658  False   \n",
       "1  False  460059               Burn Out      32.045  False   \n",
       "2  False   86674          パーク アンド ラブホテル       1.677  False   \n",
       "3  False  169298                 Bullet      11.017  False   \n",
       "4  False  550654    Every Other Holiday       6.878  False   \n",
       "\n",
       "                                       url  \\\n",
       "0   https://www.themoviedb.org/movie/52826   \n",
       "1  https://www.themoviedb.org/movie/460059   \n",
       "2   https://www.themoviedb.org/movie/86674   \n",
       "3  https://www.themoviedb.org/movie/169298   \n",
       "4  https://www.themoviedb.org/movie/550654   \n",
       "\n",
       "                                          poster_url  Action  Adventure  \\\n",
       "0  https://www.themoviedb.org/t/p/w500//ph2L3Rp3X...     0.0        0.0   \n",
       "1  https://www.themoviedb.org/t/p/w500//3LeFOvzjZ...     0.0        0.0   \n",
       "2  https://www.themoviedb.org/t/p/w500//8KAgoOwi3...     0.0        0.0   \n",
       "3  https://www.themoviedb.org/t/p/w500//oSYnKLSl1...     1.0        0.0   \n",
       "4  https://www.themoviedb.org/t/p/w500//8DetMslOB...     0.0        0.0   \n",
       "\n",
       "   Animation  ...  Romance  Science Fiction  TV Movie  Thriller  War  Western  \\\n",
       "0        0.0  ...      0.0              1.0       0.0       0.0  0.0      0.0   \n",
       "1        0.0  ...      0.0              0.0       0.0       1.0  0.0      0.0   \n",
       "2        0.0  ...      1.0              0.0       0.0       0.0  0.0      0.0   \n",
       "3        0.0  ...      0.0              0.0       0.0       0.0  0.0      0.0   \n",
       "4        0.0  ...      0.0              0.0       1.0       0.0  0.0      0.0   \n",
       "\n",
       "                          filename                   genre_id  \\\n",
       "0  ph2L3Rp3XbMzxuLTTQBxvtNgF13.jpg              [878, 35, 14]   \n",
       "1  3LeFOvzjZuIC7cQiXDeSIy1ym7a.jpg                   [28, 53]   \n",
       "2  8KAgoOwi3KVtp8pwnmtsfoQSkEh.jpg                [18, 10749]   \n",
       "3  oSYnKLSl11aoZqJQIK9zoV63l3D.jpg               [28, 80, 53]   \n",
       "4  8DetMslOBOBKsT2cXBDBHP0ayVF.jpg  [10770, 10751, 10749, 18]   \n",
       "\n",
       "                         genre_ids2                     genre_ids2_list  \n",
       "0  [Science Fiction,Comedy,Fantasy]  [Science Fiction, Comedy, Fantasy]  \n",
       "1                 [Action,Thriller]                  [Action, Thriller]  \n",
       "2                   [Drama,Romance]                    [Drama, Romance]  \n",
       "3           [Action,Crime,Thriller]           [Action, Crime, Thriller]  \n",
       "4   [TV Movie,Family,Romance,Drama]  [TV Movie, Family, Romance, Drama]  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(parquet_fname)\n",
    "#df['genre_id'] = df['genre_id'].apply(lambda x: list(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['genre_id'].head().iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>video</th>\n",
       "      <th>url</th>\n",
       "      <th>poster_url</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>filename</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>genre_ids2</th>\n",
       "      <th>genre_ids2_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>52826</td>\n",
       "      <td>Nothing Lasts Forever</td>\n",
       "      <td>5.658</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/52826</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//ph2L3Rp3X...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ph2L3Rp3XbMzxuLTTQBxvtNgF13.jpg</td>\n",
       "      <td>[878, 35, 14]</td>\n",
       "      <td>[Science Fiction,Comedy,Fantasy]</td>\n",
       "      <td>[Science Fiction, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>460059</td>\n",
       "      <td>Burn Out</td>\n",
       "      <td>32.045</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/460059</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//3LeFOvzjZ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3LeFOvzjZuIC7cQiXDeSIy1ym7a.jpg</td>\n",
       "      <td>[28, 53]</td>\n",
       "      <td>[Action,Thriller]</td>\n",
       "      <td>[Action, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>86674</td>\n",
       "      <td>パーク アンド ラブホテル</td>\n",
       "      <td>1.677</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/86674</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//8KAgoOwi3...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8KAgoOwi3KVtp8pwnmtsfoQSkEh.jpg</td>\n",
       "      <td>[18, 10749]</td>\n",
       "      <td>[Drama,Romance]</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>169298</td>\n",
       "      <td>Bullet</td>\n",
       "      <td>11.017</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/169298</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//oSYnKLSl1...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>oSYnKLSl11aoZqJQIK9zoV63l3D.jpg</td>\n",
       "      <td>[28, 80, 53]</td>\n",
       "      <td>[Action,Crime,Thriller]</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>550654</td>\n",
       "      <td>Every Other Holiday</td>\n",
       "      <td>6.878</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/550654</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//8DetMslOB...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8DetMslOBOBKsT2cXBDBHP0ayVF.jpg</td>\n",
       "      <td>[10770, 10751, 10749, 18]</td>\n",
       "      <td>[TV Movie,Family,Romance,Drama]</td>\n",
       "      <td>[TV Movie, Family, Romance, Drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult      id         original_title  popularity  video  \\\n",
       "0  False   52826  Nothing Lasts Forever       5.658  False   \n",
       "1  False  460059               Burn Out      32.045  False   \n",
       "2  False   86674          パーク アンド ラブホテル       1.677  False   \n",
       "3  False  169298                 Bullet      11.017  False   \n",
       "4  False  550654    Every Other Holiday       6.878  False   \n",
       "\n",
       "                                       url  \\\n",
       "0   https://www.themoviedb.org/movie/52826   \n",
       "1  https://www.themoviedb.org/movie/460059   \n",
       "2   https://www.themoviedb.org/movie/86674   \n",
       "3  https://www.themoviedb.org/movie/169298   \n",
       "4  https://www.themoviedb.org/movie/550654   \n",
       "\n",
       "                                          poster_url  Action  Adventure  \\\n",
       "0  https://www.themoviedb.org/t/p/w500//ph2L3Rp3X...     0.0        0.0   \n",
       "1  https://www.themoviedb.org/t/p/w500//3LeFOvzjZ...     0.0        0.0   \n",
       "2  https://www.themoviedb.org/t/p/w500//8KAgoOwi3...     0.0        0.0   \n",
       "3  https://www.themoviedb.org/t/p/w500//oSYnKLSl1...     1.0        0.0   \n",
       "4  https://www.themoviedb.org/t/p/w500//8DetMslOB...     0.0        0.0   \n",
       "\n",
       "   Animation  ...  Romance  Science Fiction  TV Movie  Thriller  War  Western  \\\n",
       "0        0.0  ...      0.0              1.0       0.0       0.0  0.0      0.0   \n",
       "1        0.0  ...      0.0              0.0       0.0       1.0  0.0      0.0   \n",
       "2        0.0  ...      1.0              0.0       0.0       0.0  0.0      0.0   \n",
       "3        0.0  ...      0.0              0.0       0.0       0.0  0.0      0.0   \n",
       "4        0.0  ...      0.0              0.0       1.0       0.0  0.0      0.0   \n",
       "\n",
       "                          filename                   genre_id  \\\n",
       "0  ph2L3Rp3XbMzxuLTTQBxvtNgF13.jpg              [878, 35, 14]   \n",
       "1  3LeFOvzjZuIC7cQiXDeSIy1ym7a.jpg                   [28, 53]   \n",
       "2  8KAgoOwi3KVtp8pwnmtsfoQSkEh.jpg                [18, 10749]   \n",
       "3  oSYnKLSl11aoZqJQIK9zoV63l3D.jpg               [28, 80, 53]   \n",
       "4  8DetMslOBOBKsT2cXBDBHP0ayVF.jpg  [10770, 10751, 10749, 18]   \n",
       "\n",
       "                         genre_ids2                     genre_ids2_list  \n",
       "0  [Science Fiction,Comedy,Fantasy]  [Science Fiction, Comedy, Fantasy]  \n",
       "1                 [Action,Thriller]                  [Action, Thriller]  \n",
       "2                   [Drama,Romance]                    [Drama, Romance]  \n",
       "3           [Action,Crime,Thriller]           [Action, Crime, Thriller]  \n",
       "4   [TV Movie,Family,Romance,Drama]  [TV Movie, Family, Romance, Drama]  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15015 entries, 0 to 15440\n",
      "Data columns (total 30 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   adult            15015 non-null  bool   \n",
      " 1   id               15015 non-null  int64  \n",
      " 2   original_title   15015 non-null  object \n",
      " 3   popularity       15015 non-null  float64\n",
      " 4   video            15015 non-null  bool   \n",
      " 5   url              15015 non-null  object \n",
      " 6   poster_url       15015 non-null  object \n",
      " 7   Action           15015 non-null  float64\n",
      " 8   Adventure        15015 non-null  float64\n",
      " 9   Animation        15015 non-null  float64\n",
      " 10  Comedy           15015 non-null  float64\n",
      " 11  Crime            15015 non-null  float64\n",
      " 12  Documentary      15015 non-null  float64\n",
      " 13  Drama            15015 non-null  float64\n",
      " 14  Family           15015 non-null  float64\n",
      " 15  Fantasy          15015 non-null  float64\n",
      " 16  History          15015 non-null  float64\n",
      " 17  Horror           15015 non-null  float64\n",
      " 18  Music            15015 non-null  float64\n",
      " 19  Mystery          15015 non-null  float64\n",
      " 20  Romance          15015 non-null  float64\n",
      " 21  Science Fiction  15015 non-null  float64\n",
      " 22  TV Movie         15015 non-null  float64\n",
      " 23  Thriller         15015 non-null  float64\n",
      " 24  War              15015 non-null  float64\n",
      " 25  Western          15015 non-null  float64\n",
      " 26  filename         15015 non-null  object \n",
      " 27  genre_id         15015 non-null  object \n",
      " 28  genre_ids2       15015 non-null  object \n",
      " 29  genre_ids2_list  15015 non-null  object \n",
      "dtypes: bool(2), float64(20), int64(1), object(7)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1ChqgNRK0py"
   },
   "source": [
    " Create ImageGenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPXBrisCLgl2"
   },
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_model_densnet169 = MODEL_DIR + \"densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "fname_model_vgg16 = MODEL_DIR + \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hwX1XsBiduav"
   },
   "outputs": [],
   "source": [
    "def model_create():\n",
    "    # load model\n",
    "    model = VGG16(include_top=False,  \n",
    "                  input_shape=(299,299, 3),\n",
    "                  weights=fname_model_vgg16)\n",
    "    model_name = \"VGG16\"\n",
    "    \n",
    "    #model = DenseNet169(include_top=False,  \n",
    "    #                    input_shape=(299,299, 3),\n",
    "    #                    weights=fname_model_densnet169)\n",
    "\n",
    "   \n",
    "    #x= layers.Flatten()(model.layers[-1].output)\n",
    "    x=layers.GlobalMaxPool2D()(model.layers[-1].output)\n",
    "    \n",
    "    #x= layers.Dense(128, activation='relu')(x)\n",
    "    x= layers.Dense(1024, activation='relu')(x)\n",
    "    x= layers.Dense(128, activation='relu')(x)\n",
    "    \n",
    "    #x= layers.Dropout(0.5)(x)\n",
    "    #classifications = layers.Dense(len(train_generator.class_indices), activation='sigmoid')(x)\n",
    "    classifications = layers.Dense(number_of_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=model.inputs, \n",
    "                  outputs=classifications,\n",
    "                  name=model_name)\n",
    "\n",
    "    #display(model.summary())\n",
    "    return model, model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we implemented a standard DenseNet-169 architecture with similar modifications. The final\n",
    "fully-connected layer of 1000 units was once again replaced by 3 sequential fully-connected layers of\n",
    "3\n",
    "1024, 128, and 7 units with ReLU, ReLU, and sigmoid activations respectively. The entire model\n",
    "consists of 14,479,943 parameters, out of which, 14,321,543 were trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file model_checkpoints already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir model_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime Context: 56_CPU\n",
      "Data pipeline using tf.data\n",
      "12012 training datasets, using 19 classes\n",
      "3003 validation datasets, unsing 19 classes\n",
      "23\n",
      "stopping at 18\n",
      "create callbacks\n",
      "model fit\n",
      "Epoch 1/2\n",
      "  1/188 [..............................] - ETA: 0s - loss: 0.7141 - categorical_accuracy: 0.0156 - auc: 0.4125 - f1_micro: 0.1033 - f1_macro: 0.0982 - f1_score_weighted: 0.1273WARNING:tensorflow:From C:\\Users\\A291127E01\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "188/188 [==============================] - 3148s 17s/step - loss: 0.2160 - categorical_accuracy: 0.0981 - auc: 0.5771 - f1_micro: 0.0111 - f1_macro: 0.0109 - f1_score_weighted: 0.0109 - val_loss: 0.2042 - val_categorical_accuracy: 0.1249 - val_auc: 0.6570 - val_f1_micro: 0.0102 - val_f1_macro: 0.0099 - val_f1_score_weighted: 0.0096\n",
      "Epoch 2/2\n",
      "188/188 [==============================] - 3094s 16s/step - loss: 0.2015 - categorical_accuracy: 0.1464 - auc: 0.6533 - f1_micro: 0.0276 - f1_macro: 0.0228 - f1_score_weighted: 0.0230 - val_loss: 0.2004 - val_categorical_accuracy: 0.1449 - val_auc: 0.6830 - val_f1_micro: 0.0329 - val_f1_macro: 0.0266 - val_f1_score_weighted: 0.0256\n",
      "Saving final model\n",
      "Saving final model weights\n",
      "Time spend for current run: 6275.7764 seconds => 104m 35s\n"
     ]
    }
   ],
   "source": [
    "#tf.debugging.set_log_device_placement(True)\n",
    "l_rtc_names = [            \n",
    "    #\"2-GPU_MirroredStrategy\",\n",
    "    #\"2-GPU_CentralStorageStrategy\",        \n",
    "    #\"1-GPU\",    \n",
    "    \"56_CPU\"\n",
    "    #\"2-GPU_MirroredStrategy_NCCL-All-Reduced\",\n",
    "]\n",
    "l_rtc = [        \n",
    "    #tf.distribute.MirroredStrategy().scope(),        \n",
    "    #tf.distribute.experimental.CentralStorageStrategy().scope(),        \n",
    "    #tf.device(\"/GPU:0\"),       \n",
    "    tf.device(\"/CPU:0\"),\n",
    "    #tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce()).scope(),                \n",
    "]\n",
    "for dp in [DP_TFDATA]:\n",
    "    for i, runtime_context in enumerate(l_rtc):   \n",
    "        print(f\"Runtime Context: {l_rtc_names[i]}\")\n",
    "\n",
    "        # Start time measurement\n",
    "        tic = time.perf_counter()\n",
    "\n",
    "        # Create data pipeline\n",
    "        print(dp)\n",
    "        df_train, df_valid = skms.train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "\n",
    "        if dp == DP_IMGGEN:\n",
    "            datagen = ImageDataGenerator(rescale=1 / 255.)#, validation_split=0.1)\n",
    "\n",
    "            train_generator = datagen.flow_from_dataframe(\n",
    "                dataframe=df_train,\n",
    "                directory=IMAGES_DIR,\n",
    "                x_col=\"filename\",\n",
    "                y_col=\"genre_id\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                seed=SEED,\n",
    "                shuffle=True,\n",
    "                class_mode=\"categorical\",    \n",
    "                target_size=(299, 299),\n",
    "                subset='training',\n",
    "                validate_filenames=True\n",
    "            )\n",
    "\n",
    "            valid_generator = datagen.flow_from_dataframe(\n",
    "                dataframe=df_valid,\n",
    "                directory=IMAGES_DIR,\n",
    "                x_col=\"filename\",\n",
    "                y_col=\"genre_id\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                seed=SEED,\n",
    "                shuffle=False,\n",
    "                class_mode=\"categorical\",\n",
    "                target_size=(299, 299),\n",
    "                subset='training',\n",
    "                validate_filenames=True\n",
    "            )\n",
    "        else:\n",
    "            X_train = df_train.filename.to_numpy()\n",
    "            y_train = df_train[LABEL_COLS].to_numpy()\n",
    "            X_valid = df_valid.filename.to_numpy()\n",
    "            y_valid = df_valid[LABEL_COLS].to_numpy()\n",
    "\n",
    "            train_generator = create_dataset(X_train, y_train, cache=True)\n",
    "            valid_generator = create_dataset(X_valid, y_valid, cache=True)\n",
    "\n",
    "            print(f\"{len(X_train)} training datasets, using {y_train.shape[1]} classes\")\n",
    "            print(f\"{len(X_valid)} validation datasets, unsing {y_valid.shape[1]} classes\")\n",
    "\n",
    "        if dp == DP_IMGGEN:\n",
    "            # show class indicies\n",
    "            print(train_generator.class_indices)\n",
    "            print('length:', len(train_generator.class_indices))\n",
    "\n",
    "            list(train_generator.class_indices.keys())\n",
    "\n",
    "            #https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras\n",
    "            #In order to calculate the class weight do the following\n",
    "            class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                          np.array(list(train_generator.class_indices.keys()),dtype=\"int\"), \n",
    "                                                          np.array(df.genre_id.explode(),dtype=\"int\"))\n",
    "\n",
    "            class_weights_genre_id = dict(zip(list(train_generator.class_indices), class_weights))\n",
    "            display(class_weights_genre_id)\n",
    "            class_weights = dict(zip(list(range(len(class_weights))), class_weights))\n",
    "            print(class_weights)\n",
    "\n",
    "            map_gender={\"28\":\"Action\",\n",
    "            \"12\":\"Adventure\",\n",
    "            \"16\":\"Animation\",\n",
    "            \"35\":\"Comedy\",\n",
    "            \"80\":\"Crime\",\n",
    "            \"99\":\"Documentary\",\n",
    "            \"18\":\"Drama\",\n",
    "            \"10751\":\"Family\",\n",
    "            \"14\":\"Fantasy\",\n",
    "            \"36\":\t\"History\",\n",
    "            \"27\":\"Horror\",\n",
    "            \"10402\"\t:\"Music\",\n",
    "            \"9648\":\"Mystery\",\n",
    "            \"10749\":\"Romance\",\n",
    "            \"878\"\t:\"Science Fiction\",\n",
    "            \"10770\":\"TV Movie\",\n",
    "            \"53\":\"Thriller\",\n",
    "            \"10752\":\"War\",\n",
    "            \"37\":\"Western\"}\n",
    "\n",
    "            series_genre_id_counts = df.genre_id.explode().value_counts()\n",
    "            series_genre_id_counts\n",
    "            df_genre = pd.DataFrame(series_genre_id_counts)\n",
    "            df_genre[\"id\"] = df_genre.index\n",
    "            df_genre.rename(columns={\"genre_id\" : \"count\"},inplace=True)\n",
    "            df_genre[\"name\"] = df_genre[\"id\"].apply(lambda x : map_gender[str(x)])\n",
    "            df_genre[\"weight\"] = df_genre[\"id\"].apply(lambda x : class_weights_genre_id[x])\n",
    "            df_genre.sort_values(by=\"count\")\n",
    "\n",
    "            number_of_classes = len(train_generator.class_indices)\n",
    "        else:\n",
    "            class_weights = None\n",
    "            number_of_classes = len(LABEL_COLS)            \n",
    "\n",
    "        # Create and train model\n",
    "        with runtime_context:    \n",
    "            model, model_name = model_create()\n",
    "\n",
    "            # Define Tensorflow callback log-entry\n",
    "            model_name_full = f\"{model.name}_{l_rtc_names[i]}_{dt.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "            tb_logdir = f\"{TENSORBOARD_LOGDIR}{model_name_full}\"\n",
    "            #checkpoint_path = \"model_checkpoints/saved-model-06-0.46.hdf5\"\n",
    "            #model.load_weights(checkpoint_path)\n",
    "\n",
    "            # mark loaded layers as not trainable\n",
    "            # except last layer\n",
    "            leng = len(model.layers)\n",
    "            print(leng)\n",
    "            for i,layer in enumerate(model.layers):\n",
    "                if leng-i == 5:\n",
    "                  print(\"stopping at\",i)\n",
    "                  break\n",
    "                layer.trainable = False\n",
    "\n",
    "            # Def metrics\n",
    "            threshold = 0.35\n",
    "            f1_micro = tfa.metrics.F1Score(num_classes=19, average='micro', name='f1_micro',threshold=threshold), \n",
    "            f1_macro = tfa.metrics.F1Score(num_classes=19, average='macro', name='f1_macro',threshold=threshold)\n",
    "            f1_weighted = tfa.metrics.F1Score(num_classes=19,  average='weighted', name='f1_score_weighted',threshold=threshold)\n",
    "\n",
    "            # Compile model\n",
    "            model.compile(\n",
    "                optimizer='adam', \n",
    "                loss=\"binary_crossentropy\", \n",
    "                metrics=[\"categorical_accuracy\",\n",
    "                         tf.keras.metrics.AUC(multi_label = True),#,label_weights=class_weights),\n",
    "                         f1_micro,\n",
    "                         f1_macro,\n",
    "                         f1_weighted,\n",
    "                        ])\n",
    "\n",
    "            print(\"create callbacks\")\n",
    "            #filepath = \"model_checkpoints/{model_name}_saved-model-{epoch:02d}-{val_f1_score_weighted:.2f}.hdf5\"\n",
    "            #cb_checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score_weighted', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "            cb_tensorboard = TensorBoard(\n",
    "                log_dir = tb_logdir,\n",
    "                histogram_freq=0, \n",
    "                update_freq='epoch',\n",
    "                write_graph=True, \n",
    "                write_images=False)\n",
    "            #callbacks_list = [cb_checkpoint, cb_tensorboard]\n",
    "            #callbacks_list = [cb_checkpoint]\n",
    "            callbacks_list = [cb_tensorboard]\n",
    "\n",
    "            # Train model\n",
    "            print(\"model fit\")\n",
    "            history = model.fit(\n",
    "                train_generator,\n",
    "                validation_data=valid_generator,\n",
    "                epochs=EPOCHS,\n",
    "                # reduce steps per epochs for faster epochs\n",
    "                #steps_per_epoch = math.ceil(266957 / BATCH_SIZE /8),\n",
    "                #class_weight = class_weights,\n",
    "                callbacks=callbacks_list,\n",
    "                use_multiprocessing=False\n",
    "            )\n",
    "\n",
    "            print(\"Saving final model\")\n",
    "            #model.save(MODEL_DIR + model_name_full)\n",
    "\n",
    "            print(\"Saving final model weights\")\n",
    "            #model.save_weights(MODEL_DIR + model_name_full + \".ckpt\")\n",
    "\n",
    "            # Measure time of loop\n",
    "            toc = time.perf_counter()\n",
    "            secs_all = toc - tic\n",
    "            mins = int(secs_all / 60)\n",
    "            secs = int((secs_all - mins*60))\n",
    "            print(f\"Time spend for current run: {secs_all:0.4f} seconds => {mins}m {secs}s\")\n",
    "\n",
    "            #print(\"Reset GUPs\")\n",
    "            #cuda.select_device(0)\n",
    "            #cuda.reset()\n",
    "            #device = cuda.get_current_device()\n",
    "            #device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04333003, 0.06330013, 0.01017892, ..., 0.05667298, 0.10052919,\n",
       "        0.03578316],\n",
       "       [0.05460956, 0.0506499 , 0.00554478, ..., 0.04023005, 0.12983356,\n",
       "        0.05958107],\n",
       "       [0.03774279, 0.06244115, 0.14584701, ..., 0.03503251, 0.04352151,\n",
       "        0.01338559],\n",
       "       ...,\n",
       "       [0.06977029, 0.04619539, 0.01952854, ..., 0.07278735, 0.07186844,\n",
       "        0.03285542],\n",
       "       [0.04890267, 0.11080675, 0.32461283, ..., 0.01426101, 0.03933338,\n",
       "        0.05369532],\n",
       "       [0.05003528, 0.13841233, 0.01661889, ..., 0.01224749, 0.04455657,\n",
       "        0.12601565]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012278266"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PrefetchDataset' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6f3c665d25cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0me\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PrefetchDataset' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "y_true = [ [1 if i in e else 0 for i in range(19)] for e in valid_generator.labels]\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "ths = np.linspace(0.1, 0.5, 10)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'threshold': ths, \n",
    "    'f1-micro': [f1_score(y_true, (y_pred > th)*1., average=\"micro\") for th in ths],\n",
    "    'f1-weighted': [f1_score(y_true, (y_pred > th)*1., average=\"weighted\") for th in ths],\n",
    "    'class' : \"all\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "ths = np.linspace(0.1, 0.5, 9)\n",
    "\n",
    "df_ths = pd.DataFrame({'threshold' : ths}\n",
    ")\n",
    "\n",
    "for cl in range(19):\n",
    "    col = pd.DataFrame({f'f1-class_{cl}': [f1_score(y_true[:,cl], (y_pred[:,cl] > th)*1.) for th in ths]          \n",
    "                       })\n",
    "    df_ths=pd.concat([df_ths,col],axis=\"columns\")\n",
    "\n",
    "df_ths.style.highlight_max(color = 'lightgreen', axis = 0)\n",
    "df_ths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_index=df_ths.iloc[:,1:].idxmax(axis=0)\n",
    "class_thresholds = df_ths.threshold[argmax_index].values\n",
    "class_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true, (y_pred > class_thresholds)*1., average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true, (y_pred > class_thresholds)*1., average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[:,3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:,3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_genre.sort_values(by=\"count\",ascending=False)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_generator.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_genre_ids = df_genre.sort_values(by=\"count\",ascending=False)[:7]\n",
    "display(top_n_genre_ids)\n",
    "top_n_genre_col_pos = {i:map_gender[str(e)] for i,e in enumerate(list(valid_generator.class_indices.keys())) if e in top_n_genre_ids.values}\n",
    "display(top_n_genre_col_pos)\n",
    "#mask_top_n_genre_ids = [(e in top_n_genre_ids.values) for e in list(valid_generator.class_indices.keys())]\n",
    "#mask_top_n_genre_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes=19\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], \n",
    "                                  y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
    "\n",
    "for i, color in zip(top_n_genre_col_pos.keys(), colors):#zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             #''.format(map_gender[str(i)], roc_auc[i]))\n",
    "             ''.format(top_n_genre_col_pos[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.filename=='wdju5uQUMy2jjeqdKroI6VklYbY.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
