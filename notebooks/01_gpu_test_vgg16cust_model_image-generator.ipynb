{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJCMwRx9_4rN"
   },
   "source": [
    "> # AIDA with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7yzKetZAK3s"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_VISIBLE_DEVICES']='-1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iLciMje9AOmB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "#https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.densenet import DenseNet169\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from numba import cuda\n",
    "\n",
    "#from wcs.google import google_drive_share\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "#from google.colab import drive\n",
    "import src.helper.helper as hlp\n",
    "import src.helper.const as const\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcfsOKfzC2N6"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls $IMAGES_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "DIR = './'\n",
    "DATA_DIR_POSTER = DIR + '../data/raw/posters_v3/'\n",
    "DATA_DIR_INTERIM = DIR + \"../data/interim/\"\n",
    "DATA_DIR_RAW = DIR + \"../data/raw/\"\n",
    "MODEL_DIR = DIR + \"../models/\"\n",
    "BASE_DIR = DIR\n",
    "IMAGES_DIR = DATA_DIR_POSTER\n",
    "SEED = const.SEED\n",
    "TENSORBOARD_LOGDIR = DIR + \"tensorboard_logs/scalars/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_devices():\n",
    "    # Check GPUs\n",
    "    num_gpu = len(tf.config.list_physical_devices('GPU'))\n",
    "    print(\"Num GPUs Available: \", num_gpu)\n",
    "\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"{f'Physical GPU Device: {gpus}' if gpus else 'No GPU available'}\")\n",
    "\n",
    "    if gpus:\n",
    "        # Restrict TensorFlow to only allocate 6GB of memory on the first GPU\n",
    "        try:\n",
    "            \"\"\"\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"Set memory growth for {len(gpus)} physical GPU(s)\")\n",
    "            \"\"\"\n",
    "            mem_lim = 10*1024  # 6GB\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpus[0],\n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=mem_lim)])        \n",
    "            #logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            #print(f\"Set memory usage to {mem_lim/1000} GB for {len(gpus)} physical GPU(s) -> {len(logical_gpus)} logical GPU(s)\")\n",
    "            print(f\"Set memory usage to {mem_lim/1000} GB for {len(gpus)} physical GPU(s)\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            # Virtual devices must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "        print(\"GPU(s) will be automatically choosen for model calculations below.\")\n",
    "    else:\n",
    "        print(\"CPUs will be automatically choosen for model calculations below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA1fV-j_KX0L"
   },
   "source": [
    "# Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "acVfQ8KqKlaI"
   },
   "outputs": [],
   "source": [
    "#parquet_fname = DATA_DIR_INTERIM + \"df_train_unbalanced_v3.gzip\"\n",
    "parquet_fname = DATA_DIR_INTERIM + \"df_train_balanced_v3.gzip\"\n",
    "#!rm $parquet_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>video</th>\n",
       "      <th>url</th>\n",
       "      <th>poster_url</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>filename</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>genre_ids2</th>\n",
       "      <th>genre_ids2_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>52826</td>\n",
       "      <td>Nothing Lasts Forever</td>\n",
       "      <td>5.658</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/52826</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//ph2L3Rp3X...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ph2L3Rp3XbMzxuLTTQBxvtNgF13.jpg</td>\n",
       "      <td>[878, 35, 14]</td>\n",
       "      <td>[Science Fiction,Comedy,Fantasy]</td>\n",
       "      <td>[Science Fiction, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>460059</td>\n",
       "      <td>Burn Out</td>\n",
       "      <td>32.045</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/460059</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//3LeFOvzjZ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3LeFOvzjZuIC7cQiXDeSIy1ym7a.jpg</td>\n",
       "      <td>[28, 53]</td>\n",
       "      <td>[Action,Thriller]</td>\n",
       "      <td>[Action, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>86674</td>\n",
       "      <td>パーク アンド ラブホテル</td>\n",
       "      <td>1.677</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/86674</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//8KAgoOwi3...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8KAgoOwi3KVtp8pwnmtsfoQSkEh.jpg</td>\n",
       "      <td>[18, 10749]</td>\n",
       "      <td>[Drama,Romance]</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>169298</td>\n",
       "      <td>Bullet</td>\n",
       "      <td>11.017</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/169298</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//oSYnKLSl1...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>oSYnKLSl11aoZqJQIK9zoV63l3D.jpg</td>\n",
       "      <td>[28, 80, 53]</td>\n",
       "      <td>[Action,Crime,Thriller]</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>550654</td>\n",
       "      <td>Every Other Holiday</td>\n",
       "      <td>6.878</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/550654</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//8DetMslOB...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8DetMslOBOBKsT2cXBDBHP0ayVF.jpg</td>\n",
       "      <td>[10770, 10751, 10749, 18]</td>\n",
       "      <td>[TV Movie,Family,Romance,Drama]</td>\n",
       "      <td>[TV Movie, Family, Romance, Drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult      id         original_title  popularity  video  \\\n",
       "0  False   52826  Nothing Lasts Forever       5.658  False   \n",
       "1  False  460059               Burn Out      32.045  False   \n",
       "2  False   86674          パーク アンド ラブホテル       1.677  False   \n",
       "3  False  169298                 Bullet      11.017  False   \n",
       "4  False  550654    Every Other Holiday       6.878  False   \n",
       "\n",
       "                                       url  \\\n",
       "0   https://www.themoviedb.org/movie/52826   \n",
       "1  https://www.themoviedb.org/movie/460059   \n",
       "2   https://www.themoviedb.org/movie/86674   \n",
       "3  https://www.themoviedb.org/movie/169298   \n",
       "4  https://www.themoviedb.org/movie/550654   \n",
       "\n",
       "                                          poster_url  Action  Adventure  \\\n",
       "0  https://www.themoviedb.org/t/p/w500//ph2L3Rp3X...     0.0        0.0   \n",
       "1  https://www.themoviedb.org/t/p/w500//3LeFOvzjZ...     0.0        0.0   \n",
       "2  https://www.themoviedb.org/t/p/w500//8KAgoOwi3...     0.0        0.0   \n",
       "3  https://www.themoviedb.org/t/p/w500//oSYnKLSl1...     1.0        0.0   \n",
       "4  https://www.themoviedb.org/t/p/w500//8DetMslOB...     0.0        0.0   \n",
       "\n",
       "   Animation  ...  Romance  Science Fiction  TV Movie  Thriller  War  Western  \\\n",
       "0        0.0  ...      0.0              1.0       0.0       0.0  0.0      0.0   \n",
       "1        0.0  ...      0.0              0.0       0.0       1.0  0.0      0.0   \n",
       "2        0.0  ...      1.0              0.0       0.0       0.0  0.0      0.0   \n",
       "3        0.0  ...      0.0              0.0       0.0       0.0  0.0      0.0   \n",
       "4        0.0  ...      0.0              0.0       1.0       0.0  0.0      0.0   \n",
       "\n",
       "                          filename                   genre_id  \\\n",
       "0  ph2L3Rp3XbMzxuLTTQBxvtNgF13.jpg              [878, 35, 14]   \n",
       "1  3LeFOvzjZuIC7cQiXDeSIy1ym7a.jpg                   [28, 53]   \n",
       "2  8KAgoOwi3KVtp8pwnmtsfoQSkEh.jpg                [18, 10749]   \n",
       "3  oSYnKLSl11aoZqJQIK9zoV63l3D.jpg               [28, 80, 53]   \n",
       "4  8DetMslOBOBKsT2cXBDBHP0ayVF.jpg  [10770, 10751, 10749, 18]   \n",
       "\n",
       "                         genre_ids2                     genre_ids2_list  \n",
       "0  [Science Fiction,Comedy,Fantasy]  [Science Fiction, Comedy, Fantasy]  \n",
       "1                 [Action,Thriller]                  [Action, Thriller]  \n",
       "2                   [Drama,Romance]                    [Drama, Romance]  \n",
       "3           [Action,Crime,Thriller]           [Action, Crime, Thriller]  \n",
       "4   [TV Movie,Family,Romance,Drama]  [TV Movie, Family, Romance, Drama]  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(parquet_fname)\n",
    "#df['genre_id'] = df['genre_id'].apply(lambda x: list(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['genre_id'].head().iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>video</th>\n",
       "      <th>url</th>\n",
       "      <th>poster_url</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>filename</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>genre_ids2</th>\n",
       "      <th>genre_ids2_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>52826</td>\n",
       "      <td>Nothing Lasts Forever</td>\n",
       "      <td>5.658</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/52826</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//ph2L3Rp3X...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ph2L3Rp3XbMzxuLTTQBxvtNgF13.jpg</td>\n",
       "      <td>[878, 35, 14]</td>\n",
       "      <td>[Science Fiction,Comedy,Fantasy]</td>\n",
       "      <td>[Science Fiction, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>460059</td>\n",
       "      <td>Burn Out</td>\n",
       "      <td>32.045</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/460059</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//3LeFOvzjZ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3LeFOvzjZuIC7cQiXDeSIy1ym7a.jpg</td>\n",
       "      <td>[28, 53]</td>\n",
       "      <td>[Action,Thriller]</td>\n",
       "      <td>[Action, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>86674</td>\n",
       "      <td>パーク アンド ラブホテル</td>\n",
       "      <td>1.677</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/86674</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//8KAgoOwi3...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8KAgoOwi3KVtp8pwnmtsfoQSkEh.jpg</td>\n",
       "      <td>[18, 10749]</td>\n",
       "      <td>[Drama,Romance]</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>169298</td>\n",
       "      <td>Bullet</td>\n",
       "      <td>11.017</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/169298</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//oSYnKLSl1...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>oSYnKLSl11aoZqJQIK9zoV63l3D.jpg</td>\n",
       "      <td>[28, 80, 53]</td>\n",
       "      <td>[Action,Crime,Thriller]</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>550654</td>\n",
       "      <td>Every Other Holiday</td>\n",
       "      <td>6.878</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.themoviedb.org/movie/550654</td>\n",
       "      <td>https://www.themoviedb.org/t/p/w500//8DetMslOB...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8DetMslOBOBKsT2cXBDBHP0ayVF.jpg</td>\n",
       "      <td>[10770, 10751, 10749, 18]</td>\n",
       "      <td>[TV Movie,Family,Romance,Drama]</td>\n",
       "      <td>[TV Movie, Family, Romance, Drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult      id         original_title  popularity  video  \\\n",
       "0  False   52826  Nothing Lasts Forever       5.658  False   \n",
       "1  False  460059               Burn Out      32.045  False   \n",
       "2  False   86674          パーク アンド ラブホテル       1.677  False   \n",
       "3  False  169298                 Bullet      11.017  False   \n",
       "4  False  550654    Every Other Holiday       6.878  False   \n",
       "\n",
       "                                       url  \\\n",
       "0   https://www.themoviedb.org/movie/52826   \n",
       "1  https://www.themoviedb.org/movie/460059   \n",
       "2   https://www.themoviedb.org/movie/86674   \n",
       "3  https://www.themoviedb.org/movie/169298   \n",
       "4  https://www.themoviedb.org/movie/550654   \n",
       "\n",
       "                                          poster_url  Action  Adventure  \\\n",
       "0  https://www.themoviedb.org/t/p/w500//ph2L3Rp3X...     0.0        0.0   \n",
       "1  https://www.themoviedb.org/t/p/w500//3LeFOvzjZ...     0.0        0.0   \n",
       "2  https://www.themoviedb.org/t/p/w500//8KAgoOwi3...     0.0        0.0   \n",
       "3  https://www.themoviedb.org/t/p/w500//oSYnKLSl1...     1.0        0.0   \n",
       "4  https://www.themoviedb.org/t/p/w500//8DetMslOB...     0.0        0.0   \n",
       "\n",
       "   Animation  ...  Romance  Science Fiction  TV Movie  Thriller  War  Western  \\\n",
       "0        0.0  ...      0.0              1.0       0.0       0.0  0.0      0.0   \n",
       "1        0.0  ...      0.0              0.0       0.0       1.0  0.0      0.0   \n",
       "2        0.0  ...      1.0              0.0       0.0       0.0  0.0      0.0   \n",
       "3        0.0  ...      0.0              0.0       0.0       0.0  0.0      0.0   \n",
       "4        0.0  ...      0.0              0.0       1.0       0.0  0.0      0.0   \n",
       "\n",
       "                          filename                   genre_id  \\\n",
       "0  ph2L3Rp3XbMzxuLTTQBxvtNgF13.jpg              [878, 35, 14]   \n",
       "1  3LeFOvzjZuIC7cQiXDeSIy1ym7a.jpg                   [28, 53]   \n",
       "2  8KAgoOwi3KVtp8pwnmtsfoQSkEh.jpg                [18, 10749]   \n",
       "3  oSYnKLSl11aoZqJQIK9zoV63l3D.jpg               [28, 80, 53]   \n",
       "4  8DetMslOBOBKsT2cXBDBHP0ayVF.jpg  [10770, 10751, 10749, 18]   \n",
       "\n",
       "                         genre_ids2                     genre_ids2_list  \n",
       "0  [Science Fiction,Comedy,Fantasy]  [Science Fiction, Comedy, Fantasy]  \n",
       "1                 [Action,Thriller]                  [Action, Thriller]  \n",
       "2                   [Drama,Romance]                    [Drama, Romance]  \n",
       "3           [Action,Crime,Thriller]           [Action, Crime, Thriller]  \n",
       "4   [TV Movie,Family,Romance,Drama]  [TV Movie, Family, Romance, Drama]  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15015 entries, 0 to 15440\n",
      "Data columns (total 30 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   adult            15015 non-null  bool   \n",
      " 1   id               15015 non-null  int64  \n",
      " 2   original_title   15015 non-null  object \n",
      " 3   popularity       15015 non-null  float64\n",
      " 4   video            15015 non-null  bool   \n",
      " 5   url              15015 non-null  object \n",
      " 6   poster_url       15015 non-null  object \n",
      " 7   Action           15015 non-null  float64\n",
      " 8   Adventure        15015 non-null  float64\n",
      " 9   Animation        15015 non-null  float64\n",
      " 10  Comedy           15015 non-null  float64\n",
      " 11  Crime            15015 non-null  float64\n",
      " 12  Documentary      15015 non-null  float64\n",
      " 13  Drama            15015 non-null  float64\n",
      " 14  Family           15015 non-null  float64\n",
      " 15  Fantasy          15015 non-null  float64\n",
      " 16  History          15015 non-null  float64\n",
      " 17  Horror           15015 non-null  float64\n",
      " 18  Music            15015 non-null  float64\n",
      " 19  Mystery          15015 non-null  float64\n",
      " 20  Romance          15015 non-null  float64\n",
      " 21  Science Fiction  15015 non-null  float64\n",
      " 22  TV Movie         15015 non-null  float64\n",
      " 23  Thriller         15015 non-null  float64\n",
      " 24  War              15015 non-null  float64\n",
      " 25  Western          15015 non-null  float64\n",
      " 26  filename         15015 non-null  object \n",
      " 27  genre_id         15015 non-null  object \n",
      " 28  genre_ids2       15015 non-null  object \n",
      " 29  genre_ids2_list  15015 non-null  object \n",
      "dtypes: bool(2), float64(20), int64(1), object(7)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1ChqgNRK0py"
   },
   "source": [
    " Create ImageGenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['genre_id'] = df['genre_id'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15015 validated image filenames belonging to 19 classes.\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#df = df[1:1000]\n",
    "datagen = ImageDataGenerator(rescale=1 / 255.)#, validation_split=0.1)\n",
    "BATCH_SIZE = 64*4\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=IMAGES_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"genre_id\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",    \n",
    "    target_size=(299, 299),\n",
    "    subset='training',\n",
    "    validate_filenames=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15015 validated image filenames belonging to 19 classes.\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#datagen = ImageDataGenerator(rescale=1 / 255.)#, validation_split=0.1)\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=IMAGES_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"genre_id\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(299, 299),\n",
    "    subset='training',\n",
    "    validate_filenames=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tz11Ruq2KyQs"
   },
   "source": [
    "%%time\n",
    "datagen = ImageDataGenerator(rescale=1 / 255., validation_split=0.1)\n",
    "BATCH_SIZE = 64\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=IMAGES_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"genre_id\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",    \n",
    "    target_size=(299, 299),\n",
    "    subset='training',\n",
    "    validate_filenames=True\n",
    ")\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=IMAGES_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"genre_id\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(299, 299),\n",
    "    subset='validation',\n",
    "    validate_filenames=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1a6YhAuOLWFC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12: 0, 14: 1, 16: 2, 18: 3, 27: 4, 28: 5, 35: 6, 36: 7, 37: 8, 53: 9, 80: 10, 99: 11, 878: 12, 9648: 13, 10402: 14, 10749: 15, 10751: 16, 10752: 17, 10770: 18}\n",
      "length: 19\n"
     ]
    }
   ],
   "source": [
    "# show class indicies\n",
    "print(train_generator.class_indices)\n",
    "print('length:', len(train_generator.class_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "irTOneeqduah"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12,\n",
       " 14,\n",
       " 16,\n",
       " 18,\n",
       " 27,\n",
       " 28,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 53,\n",
       " 80,\n",
       " 99,\n",
       " 878,\n",
       " 9648,\n",
       " 10402,\n",
       " 10749,\n",
       " 10751,\n",
       " 10752,\n",
       " 10770]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SIVWsXqFduai"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: 0.9582155284906481,\n",
       " 14: 1.2180599232816118,\n",
       " 16: 1.060666245373296,\n",
       " 18: 0.3579902090231368,\n",
       " 27: 1.0810636731689363,\n",
       " 28: 0.7519680839715828,\n",
       " 35: 0.5943945091822797,\n",
       " 36: 1.5446338577501204,\n",
       " 37: 2.0033534159372515,\n",
       " 53: 0.8413175796634443,\n",
       " 80: 1.1215872207726088,\n",
       " 99: 1.2500709320470988,\n",
       " 878: 1.2785012151329391,\n",
       " 9648: 1.340393976270155,\n",
       " 10402: 1.5106720384021943,\n",
       " 10749: 0.9572266579762099,\n",
       " 10751: 1.1188813408672464,\n",
       " 10752: 1.6926142912024587,\n",
       " 10770: 1.396916613823716}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.9582155284906481,\n",
       " 1: 1.2180599232816118,\n",
       " 2: 1.060666245373296,\n",
       " 3: 0.3579902090231368,\n",
       " 4: 1.0810636731689363,\n",
       " 5: 0.7519680839715828,\n",
       " 6: 0.5943945091822797,\n",
       " 7: 1.5446338577501204,\n",
       " 8: 2.0033534159372515,\n",
       " 9: 0.8413175796634443,\n",
       " 10: 1.1215872207726088,\n",
       " 11: 1.2500709320470988,\n",
       " 12: 1.2785012151329391,\n",
       " 13: 1.340393976270155,\n",
       " 14: 1.5106720384021943,\n",
       " 15: 0.9572266579762099,\n",
       " 16: 1.1188813408672464,\n",
       " 17: 1.6926142912024587,\n",
       " 18: 1.396916613823716}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras\n",
    "from sklearn.utils import class_weight\n",
    "#In order to calculate the class weight do the following\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.array(list(train_generator.class_indices.keys()),dtype=\"int\"), \n",
    "                                                  np.array(df.genre_id.explode(),dtype=\"int\"))\n",
    "\n",
    "class_weights_genre_id = dict(zip(list(train_generator.class_indices), class_weights))\n",
    "display(class_weights_genre_id)\n",
    "class_weights = dict(zip(list(range(len(class_weights))), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MXYlHNqVduaj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>926</td>\n",
       "      <td>37</td>\n",
       "      <td>Western</td>\n",
       "      <td>2.003353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10752</th>\n",
       "      <td>1096</td>\n",
       "      <td>10752</td>\n",
       "      <td>War</td>\n",
       "      <td>1.692614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1201</td>\n",
       "      <td>36</td>\n",
       "      <td>History</td>\n",
       "      <td>1.544634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10402</th>\n",
       "      <td>1228</td>\n",
       "      <td>10402</td>\n",
       "      <td>Music</td>\n",
       "      <td>1.510672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10770</th>\n",
       "      <td>1328</td>\n",
       "      <td>10770</td>\n",
       "      <td>TV Movie</td>\n",
       "      <td>1.396917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9648</th>\n",
       "      <td>1384</td>\n",
       "      <td>9648</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>1.340394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>1451</td>\n",
       "      <td>878</td>\n",
       "      <td>Science Fiction</td>\n",
       "      <td>1.278501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1484</td>\n",
       "      <td>99</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>1.250071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1523</td>\n",
       "      <td>14</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1.218060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1654</td>\n",
       "      <td>80</td>\n",
       "      <td>Crime</td>\n",
       "      <td>1.121587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751</th>\n",
       "      <td>1658</td>\n",
       "      <td>10751</td>\n",
       "      <td>Family</td>\n",
       "      <td>1.118881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1716</td>\n",
       "      <td>27</td>\n",
       "      <td>Horror</td>\n",
       "      <td>1.081064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1749</td>\n",
       "      <td>16</td>\n",
       "      <td>Animation</td>\n",
       "      <td>1.060666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1936</td>\n",
       "      <td>12</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>0.958216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10749</th>\n",
       "      <td>1938</td>\n",
       "      <td>10749</td>\n",
       "      <td>Romance</td>\n",
       "      <td>0.957227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2205</td>\n",
       "      <td>53</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>0.841318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2467</td>\n",
       "      <td>28</td>\n",
       "      <td>Action</td>\n",
       "      <td>0.751968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3121</td>\n",
       "      <td>35</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>0.594395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5182</td>\n",
       "      <td>18</td>\n",
       "      <td>Drama</td>\n",
       "      <td>0.357990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count     id             name    weight\n",
       "37       926     37          Western  2.003353\n",
       "10752   1096  10752              War  1.692614\n",
       "36      1201     36          History  1.544634\n",
       "10402   1228  10402            Music  1.510672\n",
       "10770   1328  10770         TV Movie  1.396917\n",
       "9648    1384   9648          Mystery  1.340394\n",
       "878     1451    878  Science Fiction  1.278501\n",
       "99      1484     99      Documentary  1.250071\n",
       "14      1523     14          Fantasy  1.218060\n",
       "80      1654     80            Crime  1.121587\n",
       "10751   1658  10751           Family  1.118881\n",
       "27      1716     27           Horror  1.081064\n",
       "16      1749     16        Animation  1.060666\n",
       "12      1936     12        Adventure  0.958216\n",
       "10749   1938  10749          Romance  0.957227\n",
       "53      2205     53         Thriller  0.841318\n",
       "28      2467     28           Action  0.751968\n",
       "35      3121     35           Comedy  0.594395\n",
       "18      5182     18            Drama  0.357990"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_gender={\"28\":\"Action\",\n",
    "\"12\":\"Adventure\",\n",
    "\"16\":\"Animation\",\n",
    "\"35\":\"Comedy\",\n",
    "\"80\":\"Crime\",\n",
    "\"99\":\"Documentary\",\n",
    "\"18\":\"Drama\",\n",
    "\"10751\":\"Family\",\n",
    "\"14\":\"Fantasy\",\n",
    "\"36\":\t\"History\",\n",
    "\"27\":\"Horror\",\n",
    "\"10402\"\t:\"Music\",\n",
    "\"9648\":\"Mystery\",\n",
    "\"10749\":\"Romance\",\n",
    "\"878\"\t:\"Science Fiction\",\n",
    "\"10770\":\"TV Movie\",\n",
    "\"53\":\"Thriller\",\n",
    "\"10752\":\"War\",\n",
    "\"37\":\"Western\"}\n",
    "\n",
    "series_genre_id_counts = df.genre_id.explode().value_counts()\n",
    "series_genre_id_counts\n",
    "df_genre = pd.DataFrame(series_genre_id_counts)\n",
    "df_genre[\"id\"] = df_genre.index\n",
    "df_genre.rename(columns={\"genre_id\" : \"count\"},inplace=True)\n",
    "df_genre[\"name\"] = df_genre[\"id\"].apply(lambda x : map_gender[str(x)])\n",
    "df_genre[\"weight\"] = df_genre[\"id\"].apply(lambda x : class_weights_genre_id[x])\n",
    "df_genre.sort_values(by=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPXBrisCLgl2"
   },
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_model_densnet169 = MODEL_DIR + \"densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "fname_model_vgg16 = MODEL_DIR + \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hwX1XsBiduav"
   },
   "outputs": [],
   "source": [
    "def model_create():\n",
    "    # load model\n",
    "    model = VGG16(include_top=False,  \n",
    "                  input_shape=(299,299, 3),\n",
    "                  weights=fname_model_vgg16)\n",
    "    model_name = \"VGG16\"\n",
    "    \n",
    "    #model = DenseNet169(include_top=False,  \n",
    "    #                    input_shape=(299,299, 3),\n",
    "    #                    weights=fname_model_densnet169)\n",
    "\n",
    "    # summarize the model\n",
    "    #display(model.summary())\n",
    "    # try global average pooling instead flatten\n",
    "    \n",
    "    #x= layers.Flatten()(model.layers[-1].output)\n",
    "    x=layers.GlobalMaxPool2D()(model.layers[-1].output)\n",
    "    \n",
    "    #x= layers.Dense(128, activation='relu')(x)\n",
    "    x= layers.Dense(1024, activation='relu')(x)\n",
    "    x= layers.Dense(128, activation='relu')(x)\n",
    "    \n",
    "    #x= layers.Dropout(0.5)(x)\n",
    "    classifications = layers.Dense(len(train_generator.class_indices), activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=model.inputs, \n",
    "                  outputs=classifications,\n",
    "                  name=model_name)\n",
    "\n",
    "    return model, model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we implemented a standard DenseNet-169 architecture with similar modifications. The final\n",
    "fully-connected layer of 1000 units was once again replaced by 3 sequential fully-connected layers of\n",
    "3\n",
    "1024, 128, and 7 units with ReLU, ReLU, and sigmoid activations respectively. The entire model\n",
    "consists of 14,479,943 parameters, out of which, 14,321,543 were trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file model_checkpoints already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir model_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPU, 4 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Create 2 virtual GPUs with 5GB memory each\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        #OK, but solwer: gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "        #          tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "        #          tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "        #          tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024)],\n",
    "        gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024),tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)],\n",
    "        #Error: gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10*1024)],\n",
    "    )\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        #OK, but solwer: gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "        #          tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "        #          tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024),\n",
    "        #          tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2.5*1024)],\n",
    "        gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024),tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)],\n",
    "        #Error: gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10*1024)],\n",
    "    )\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3'], variable_device = '/device:CPU:0'\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Runtime Context: 2-GPU_MirroredStrategy\n",
      "23\n",
      "stopping at 18\n",
      "create callbacks\n",
      "model fit\n",
      "WARNING:tensorflow:From C:\\Users\\A291127E01\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\data\\ops\\multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      " 1/59 [..............................] - ETA: 0s - loss: 0.7778 - categorical_accuracy: 0.0039 - auc: 0.5007 - f1_micro: 0.1770 - f1_macro: 0.1464 - f1_score_weighted: 0.1447WARNING:tensorflow:From C:\\Users\\A291127E01\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "59/59 [==============================] - 414s 7s/step - loss: 0.3689 - categorical_accuracy: 0.2614 - auc: 0.5692 - f1_micro: 0.1636 - f1_macro: 0.0745 - f1_score_weighted: 0.1207 - val_loss: 0.3424 - val_categorical_accuracy: 0.2904 - val_auc: 0.6574 - val_f1_micro: 0.2120 - val_f1_macro: 0.0817 - val_f1_score_weighted: 0.1393\n",
      "Saving final model\n",
      "Saving final model weights\n",
      "Time spend for current run: 456.1547 seconds => 7m 36s\n",
      "Reset GUPs\n",
      "Runtime Context: 2-GPU_CentralStorageStrategy\n",
      "23\n",
      "stopping at 18\n",
      "create callbacks\n",
      "model fit\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      " 2/59 [>.............................] - ETA: 6:43 - loss: 0.6399 - categorical_accuracy: 0.0137 - auc_1: 0.5025 - f1_micro: 0.2000 - f1_macro: 0.1620 - f1_score_weighted: 0.2003WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 3.6094s vs `on_train_batch_end` time: 10.5313s). Check your callbacks.\n",
      "59/59 [==============================] - 433s 7s/step - loss: 0.3673 - categorical_accuracy: 0.2627 - auc_1: 0.5785 - f1_micro: 0.1730 - f1_macro: 0.0784 - f1_score_weighted: 0.1269 - val_loss: 0.3394 - val_categorical_accuracy: 0.3058 - val_auc_1: 0.6729 - val_f1_micro: 0.2333 - val_f1_macro: 0.0848 - val_f1_score_weighted: 0.1424\n",
      "Saving final model\n",
      "Saving final model weights\n",
      "Time spend for current run: 450.8893 seconds => 7m 30s\n",
      "Reset GUPs\n",
      "Runtime Context: 1-GPU\n",
      "23\n",
      "stopping at 18\n",
      "create callbacks\n",
      "model fit\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[256,64,299,299] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node VGG16/block1_conv1/Relu (defined at <ipython-input-24-c936b103d7db>:76) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[assert_greater_equal/Assert/AssertGuard/pivot_f/_3/_39]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[256,64,299,299] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node VGG16/block1_conv1/Relu (defined at <ipython-input-24-c936b103d7db>:76) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_26075]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-c936b103d7db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model fit\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         history = model.fit(\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aida\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[256,64,299,299] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node VGG16/block1_conv1/Relu (defined at <ipython-input-24-c936b103d7db>:76) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[assert_greater_equal/Assert/AssertGuard/pivot_f/_3/_39]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[256,64,299,299] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node VGG16/block1_conv1/Relu (defined at <ipython-input-24-c936b103d7db>:76) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_26075]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "#tf.debugging.set_log_device_placement(True)\n",
    "l_rtc_names = [    \n",
    "    \"2-GPU_MirroredStrategy\",\n",
    "    \"2-GPU_CentralStorageStrategy\",    \n",
    "    \"1-GPU\",    \n",
    "    \"2-GPU_MirroredStrategy_NCCL-All-Reduced\",\n",
    "    #\"56_CPU\"\n",
    "]\n",
    "l_rtc = [    \n",
    "    tf.distribute.MirroredStrategy().scope(),\n",
    "    tf.distribute.experimental.CentralStorageStrategy().scope(),\n",
    "    tf.device(\"/GPU:0\"),       \n",
    "    tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce()).scope(),        \n",
    "    #tf.device(\"/CPU:0\")    \n",
    "]\n",
    "for i, runtime_context in enumerate(l_rtc):   \n",
    "    print(f\"Runtime Context: {l_rtc_names[i]}\")\n",
    "\n",
    "    # Start time measurement\n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    # Init available GPUs or CPUs\n",
    "    #init_devices()\n",
    "    \n",
    "    # Create and train model\n",
    "    with runtime_context:    \n",
    "        model, model_name = model_create()\n",
    "\n",
    "        # Define Tensorflow callback log-entry\n",
    "        model_name_full = f\"{model.name}_{l_rtc_names[i]}_{dt.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "        tb_logdir = f\"{TENSORBOARD_LOGDIR}{model_name_full}\"\n",
    "        #checkpoint_path = \"model_checkpoints/saved-model-06-0.46.hdf5\"\n",
    "        #model.load_weights(checkpoint_path)\n",
    "\n",
    "        # mark loaded layers as not trainable\n",
    "        # except last layer\n",
    "        leng = len(model.layers)\n",
    "        print(leng)\n",
    "        for i,layer in enumerate(model.layers):\n",
    "            if leng-i == 5:\n",
    "              print(\"stopping at\",i)\n",
    "              break\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Def metrics\n",
    "        threshold = 0.35\n",
    "        f1_micro = tfa.metrics.F1Score(num_classes=19, average='micro', name='f1_micro',threshold=threshold), \n",
    "        f1_macro = tfa.metrics.F1Score(num_classes=19, average='macro', name='f1_macro',threshold=threshold)\n",
    "        f1_weighted = tfa.metrics.F1Score(num_classes=19,  average='weighted', name='f1_score_weighted',threshold=threshold)\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(optimizer='adam', loss=\"binary_crossentropy\", \n",
    "                  metrics=[\"categorical_accuracy\",\n",
    "                           tf.keras.metrics.AUC(multi_label = True),#,label_weights=class_weights),\n",
    "                           f1_micro,\n",
    "                           f1_macro,\n",
    "                           f1_weighted,\n",
    "                          ])\n",
    "\n",
    "        print(\"create callbacks\")\n",
    "        #filepath = \"model_checkpoints/{model_name}_saved-model-{epoch:02d}-{val_f1_score_weighted:.2f}.hdf5\"\n",
    "        #cb_checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score_weighted', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "        cb_tensorboard = TensorBoard(\n",
    "            log_dir = tb_logdir,\n",
    "            histogram_freq=0, \n",
    "            update_freq='epoch',\n",
    "            write_graph=True, \n",
    "            write_images=False)\n",
    "        #callbacks_list = [cb_checkpoint, cb_tensorboard]\n",
    "        #callbacks_list = [cb_checkpoint]\n",
    "        callbacks_list = [cb_tensorboard]\n",
    "\n",
    "        # Train model\n",
    "        print(\"model fit\")\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=valid_generator,\n",
    "            epochs=1,\n",
    "            # reduce steps per epochs for faster epochs\n",
    "            #steps_per_epoch = math.ceil(266957 / BATCH_SIZE /8),\n",
    "            #class_weight = class_weights,\n",
    "            callbacks=callbacks_list,\n",
    "            use_multiprocessing=False\n",
    "        )\n",
    "\n",
    "        print(\"Saving final model\")\n",
    "        #model.save(MODEL_DIR + model_name_full)\n",
    "\n",
    "        print(\"Saving final model weights\")\n",
    "        #model.save_weights(MODEL_DIR + model_name_full + \".ckpt\")\n",
    "\n",
    "        # Measure time of loop\n",
    "        toc = time.perf_counter()\n",
    "        secs_all = toc - tic\n",
    "        mins = int(secs_all / 60)\n",
    "        secs = int((secs_all - mins*60))\n",
    "        print(f\"Time spend for current run: {secs_all:0.4f} seconds => {mins}m {secs}s\")\n",
    "\n",
    "        print(\"Reset GUPs\")\n",
    "        #cuda.select_device(0)\n",
    "        #cuda.reset()\n",
    "        #device = cuda.get_current_device()\n",
    "        #device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [ [1 if i in e else 0 for i in range(19)] for e in valid_generator.labels]\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "ths = np.linspace(0.1, 0.5, 10)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'threshold': ths, \n",
    "    'f1-micro': [f1_score(y_true, (y_pred > th)*1., average=\"micro\") for th in ths],\n",
    "    'f1-weighted': [f1_score(y_true, (y_pred > th)*1., average=\"weighted\") for th in ths],\n",
    "    'class' : \"all\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "ths = np.linspace(0.1, 0.5, 9)\n",
    "\n",
    "df_ths = pd.DataFrame({'threshold' : ths}\n",
    ")\n",
    "\n",
    "for cl in range(19):\n",
    "    col = pd.DataFrame({f'f1-class_{cl}': [f1_score(y_true[:,cl], (y_pred[:,cl] > th)*1.) for th in ths]          \n",
    "                       })\n",
    "    df_ths=pd.concat([df_ths,col],axis=\"columns\")\n",
    "\n",
    "df_ths.style.highlight_max(color = 'lightgreen', axis = 0)\n",
    "df_ths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_index=df_ths.iloc[:,1:].idxmax(axis=0)\n",
    "class_thresholds = df_ths.threshold[argmax_index].values\n",
    "class_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true, (y_pred > class_thresholds)*1., average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true, (y_pred > class_thresholds)*1., average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[:,3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:,3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_genre.sort_values(by=\"count\",ascending=False)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_generator.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_genre_ids = df_genre.sort_values(by=\"count\",ascending=False)[:7]\n",
    "display(top_n_genre_ids)\n",
    "top_n_genre_col_pos = {i:map_gender[str(e)] for i,e in enumerate(list(valid_generator.class_indices.keys())) if e in top_n_genre_ids.values}\n",
    "display(top_n_genre_col_pos)\n",
    "#mask_top_n_genre_ids = [(e in top_n_genre_ids.values) for e in list(valid_generator.class_indices.keys())]\n",
    "#mask_top_n_genre_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes=19\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], \n",
    "                                  y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
    "\n",
    "for i, color in zip(top_n_genre_col_pos.keys(), colors):#zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             #''.format(map_gender[str(i)], roc_auc[i]))\n",
    "             ''.format(top_n_genre_col_pos[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.filename=='wdju5uQUMy2jjeqdKroI6VklYbY.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E345FF5DC0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /simple/tensorboard-plugin-profile/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E345FF5FD0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /simple/tensorboard-plugin-profile/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E34601A1C0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /simple/tensorboard-plugin-profile/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E34601A370>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /simple/tensorboard-plugin-profile/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E34601A520>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /simple/tensorboard-plugin-profile/\n",
      "ERROR: Could not find a version that satisfies the requirement tensorboard-plugin-profile\n",
      "ERROR: No matching distribution found for tensorboard-plugin-profile\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
